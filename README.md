## AlexNet 实现与训练

### 项目简介

该项目实现了经典的深度卷积神经网络 AlexNet，并在 CIFAR-10 数据集上进行了训练，以进行图像分类任务。AlexNet 是一个具有突破性的重要模型，最早在 ImageNet 大规模视觉识别挑战赛 (ILSVRC) 中表现优异，成为现代深度学习图像分类领域的开创性模型。

本项目中，我复现了 AlexNet 的结构，并对 CIFAR-10 数据集进行了训练和测试，旨在探索该模型在小规模数据集（与 ImageNet 相比）上的性能表现。最终训练结果显示模型在测试集上达到了约 83.7% 的准确率。

---

### AlexNet 模型结构

AlexNet 结构设计旨在捕捉图片的复杂特征，包含以下模块：

1. **卷积层**：五个卷积层提取特征，分别采用 3x3 或 5x5 卷积核。层间加入 ReLU 激活函数，以引入非线性。
2. **池化层**：三层最大池化层用于减小特征图尺寸，减轻计算负担和参数数量。
3. **全连接层**：两个 4096 节点的全连接层，用于捕捉高级特征；每层后加入 Dropout，防止过拟合。
4. **输出层**：最后一层为全连接层，用于将输出映射到 CIFAR-10 的 10 个类别。

---

### 数据集介绍

**CIFAR-10 数据集**包含 10 个类别的 60,000 张 32x32 像素的彩色图像，其中 50,000 张用于训练，10,000 张用于测试。10 个类别分别是：飞机、汽车、鸟、猫、鹿、狗、青蛙、马、船和卡车。

在数据预处理中，使用了以下变换：

- **图像缩放**：将图像缩放到 224x224 尺寸，以适配 AlexNet 的输入尺寸。
- **标准化**：每个通道均值为 (0.5, 0.5, 0.5)，标准差为 (0.5, 0.5, 0.5)，以加速模型收敛。

---

### 实验配置

- **硬件环境**：模型训练在 3090 进行。
- **软件环境**：Python 3.9，PyTorch 深度学习框架。

**训练参数**：

- **优化器**：随机梯度下降 (SGD)
  - 学习率：0.01
  - 动量：0.9
  - 权重衰减：0.0005
- **损失函数**：交叉熵损失
- **训练轮数**：20
- **批量大小**：64

---

### 训练与测试过程

1. **训练**：使用交叉熵损失函数，每个 epoch 后计算并输出训练损失。
2. **测试**：在测试数据上进行预测，计算准确率。

以下是模型训练与测试的详细结果：

| Epoch | Loss            | Test Accuracy |
|-------|-----------------|---------------|
| 1     | 1.930           | 47.19%        |
| 2     | 1.313           | 61.33%        |
| 3     | 0.998           | 68.35%        |
| 4     | 0.814           | 74.47%        |
| 5     | 0.697           | 76.43%        |
| 6     | 0.600           | 78.19%        |
| 7     | 0.529           | 78.89%        |
| 8     | 0.458           | 78.33%        |
| 9     | 0.408           | 78.34%        |
| 10    | 0.362           | 81.11%        |
| 11    | 0.317           | 83.11%        |
| 12    | 0.289           | 82.80%        |
| 13    | 0.265           | 81.43%        |
| 14    | 0.242           | 83.27%        |
| 15    | 0.222           | 82.39%        |
| 16    | 0.202           | 83.30%        |
| 17    | 0.184           | 82.80%        |
| 18    | 0.184           | 83.76%        |
| 19    | 0.165           | 83.23%        |
| 20    | 0.159           | 83.71%        |

---

### 结果与分析

1. **损失下降趋势**：训练过程中，损失值从 1.93 降至 0.159，整体呈现出良好的下降趋势，表明模型在不断学习和优化。
2. **准确率趋势**：在 20 个 epoch 中，测试准确率从 47.19% 提升至 83.71%。在训练初期准确率迅速上升，随后在第 10 轮左右趋于稳定。
3. **性能瓶颈**：在约 78% 测试准确率时，模型一度出现停滞（第 8-10 轮），之后逐步突破到 80%以上。这可能是由于 CIFAR-10 数据集较小、复杂度低，模型能力略显冗余。
4. **过拟合现象**：在中后期（10 轮以后），模型训练损失持续下降，但测试准确率增长较慢，存在一定的过拟合风险。Dropout 层帮助减轻了这一问题，但可以进一步调整超参数或加入正则化。

### 总结与改进方向

- **结果总结**：AlexNet 在 CIFAR-10 数据集上实现了 83.7% 的准确率，表明该模型在 CIFAR-10 上具备良好的分类能力。
- **改进方向**：
  - **数据增强**：如随机裁剪、水平翻转等，可能进一步提高泛化能力。
  - **学习率调整**：动态学习率衰减策略可帮助模型更快收敛。
  - **模型精简**：针对 CIFAR-10 尺度，简化模型层数，减少计算量和参数可能更适合训练。

---

### 使用方法

1. 安装依赖项：

   ```bash
   pip install torch torchvision
   ```

2. 运行 `main.py` 开始训练：

   ```bash
   python main.py
   ```

训练结束后，程序将输出每个 epoch 的损失和测试准确率。

---

### 参考文献

- AlexNet 原始论文：[ImageNet Classification with Deep Convolutional Neural Networks](https://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks)