# AlexNet 实现与训练

## 项目简介

该项目实现了经典的深度卷积神经网络 **AlexNet**，并在 **CIFAR-10** 数据集上进行了训练，以进行图像分类任务。AlexNet 是一个具有突破性的重要模型，最早在 ImageNet 大规模视觉识别挑战赛 (ILSVRC) 中表现优异，成为现代深度学习图像分类领域的开创性模型。

本项目中，我复现了 AlexNet 的结构，并对 CIFAR-10 数据集进行了训练和测试。旨在探索该模型在小规模数据集（与 ImageNet 相比）上的性能表现。最终训练结果显示模型在测试集上达到了约 **83.75%** 的准确率。

此外，通过与 PyTorch 官方实现的 AlexNet 进行对比，结果验证了我的自定义实现与官方实现的一致性。

---

## AlexNet 模型结构

AlexNet 结构设计旨在捕捉图片的复杂特征，包含以下模块：

1. **卷积层**：五个卷积层提取特征，分别采用 3x3 或 5x5 卷积核。层间加入 ReLU 激活函数，以引入非线性。
2. **池化层**：三层最大池化层用于减小特征图尺寸，减轻计算负担和参数数量。
3. **全连接层**：两个 4096 节点的全连接层，用于捕捉高级特征；每层后加入 Dropout，防止过拟合。
4. **输出层**：最后一层为全连接层，用于将输出映射到 CIFAR-10 的 10 个类别。

---

## 数据集介绍

**CIFAR-10 数据集**包含 10 个类别的 60,000 张 32x32 像素的彩色图像，其中 50,000 张用于训练，10,000 张用于测试。10 个类别分别是：飞机、汽车、鸟、猫、鹿、狗、青蛙、马、船和卡车。

在数据预处理中，使用了以下变换：

- **图像缩放**：将图像缩放到 224x224 尺寸，以适配 AlexNet 的输入尺寸。
- **标准化**：每个通道均值为 (0.5, 0.5, 0.5)，标准差为 (0.5, 0.5, 0.5)，以加速模型收敛。

---

## 实验配置

- **硬件环境**：模型训练在 GPU 3090 上进行。
- **软件环境**：Python 3.9，PyTorch 深度学习框架。

**训练参数**：

- **优化器**：随机梯度下降 (SGD)
  - 学习率：0.01
  - 动量：0.9
  - 权重衰减：0.0005
- **损失函数**：交叉熵损失
- **训练轮数**：20
- **批量大小**：64

---

## 训练与测试过程

1. **训练**：使用交叉熵损失函数，每个 epoch 后计算并输出训练损失。
2. **测试**：在测试数据上进行预测，计算准确率。

以下是模型训练与测试的详细结果（复现结果）：

| Epoch | Loss            | Test Accuracy |
|-------|-----------------|---------------|
| 1     | 1.963           | 44.45%        |
| 2     | 1.336           | 59.16%        |
| 3     | 1.018           | 68.14%        |
| 4     | 0.827           | 74.56%        |
| 5     | 0.707           | 76.62%        |
| 6     | 0.607           | 78.17%        |
| 7     | 0.534           | 78.62%        |
| 8     | 0.467           | 80.68%        |
| 9     | 0.409           | 79.97%        |
| 10    | 0.358           | 82.20%        |
| 11    | 0.334           | 82.71%        |
| 12    | 0.294           | 82.02%        |
| 13    | 0.262           | 81.54%        |
| 14    | 0.243           | 82.54%        |
| 15    | 0.223           | 83.09%        |
| 16    | 0.203           | 81.70%        |
| 17    | 0.183           | 83.58%        |
| 18    | 0.175           | 83.35%        |
| 19    | 0.168           | 83.75%        |
| 20    | 0.158           | 83.34%        |

---

## 结果与分析

1. **损失下降趋势**：训练过程中，损失值从 1.96 降至 0.158，整体呈现出良好的下降趋势，表明模型在不断学习和优化。
2. **准确率趋势**：在 20 个 epoch 中，测试准确率从 44.45% 提升至 83.75%。在训练初期准确率迅速上升，随后在第 10 轮左右趋于稳定。
3. **性能瓶颈**：在约 80% 测试准确率时，模型一度出现停滞（第 8-10 轮），之后逐步突破到 80%以上。这可能是由于 CIFAR-10 数据集较小、复杂度低，模型能力略显冗余。
4. **过拟合现象**：在中后期（10 轮以后），模型训练损失持续下降，但测试准确率增长较慢，存在一定的过拟合风险。Dropout 层帮助减轻了这一问题，但可以进一步调整超参数或加入正则化。

## 结果一致性验证

通过与 PyTorch 官方实现的 AlexNet 进行对比，我的自定义实现取得了几乎一致的训练损失和测试准确率。这验证了该实现的准确性与可靠性。

---

## 总结与改进方向

- **结果总结**：AlexNet 在 CIFAR-10 数据集上实现了 83.75% 的准确率，表明该模型在 CIFAR-10 上具备良好的分类能力。
- **改进方向**：
  - **数据增强**：如随机裁剪、水平翻转等，可能进一步提高泛化能力。
  - **学习率调整**：动态学习率衰减策略可帮助模型更快收敛。
  - **模型精简**：针对 CIFAR-10 尺度，简化模型层数，减少计算量和参数可能更适合训练。

---

## 使用方法

1. 安装依赖项：

   ```bash
   pip install torch torchvision matplotlib
   ```

2. 运行 `main.py` 开始训练：

   ```bash
   python main.py
   ```

训练结束后，程序将输出每个 epoch 的损失和测试准确率。

---

## 参考文献

- AlexNet 原始论文：[ImageNet Classification with Deep Convolutional Neural Networks](https://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks)